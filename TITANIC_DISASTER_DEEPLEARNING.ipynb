{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"D:/uni/KAGGLE COMPETITIONS/titanic/train.csv\")\n",
    "test = pd.read_csv(\"D:/uni/KAGGLE COMPETITIONS/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop([\"PassengerId\", \"Name\", \"Ticket\"], axis = 1, inplace = True)\n",
    "columns = train.columns    #risetto le colonne, ora che ne sono state droppate 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La variabile Survived ha 0 missing value\n",
      "La variabile Pclass ha 0 missing value\n",
      "La variabile Sex ha 0 missing value\n",
      "La variabile Age ha 177 missing value\n",
      "La variabile SibSp ha 0 missing value\n",
      "La variabile Parch ha 0 missing value\n",
      "La variabile Fare ha 0 missing value\n",
      "La variabile Cabin ha 687 missing value\n",
      "La variabile Embarked ha 2 missing value\n"
     ]
    }
   ],
   "source": [
    "for i in columns:\n",
    "    print(\"La variabile %s ha %d missing value\" % (i, train[i].isnull().values.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop([\"Cabin\"], axis = 1, inplace = True)\n",
    "columns = train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Embarked'] = train['Embarked'].fillna(train['Embarked'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Age'] = train['Age'].fillna(train['Age'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La variabile Survived ha 0 missing value\n",
      "La variabile Pclass ha 0 missing value\n",
      "La variabile Sex ha 0 missing value\n",
      "La variabile Age ha 0 missing value\n",
      "La variabile SibSp ha 0 missing value\n",
      "La variabile Parch ha 0 missing value\n",
      "La variabile Fare ha 0 missing value\n",
      "La variabile Embarked ha 0 missing value\n"
     ]
    }
   ],
   "source": [
    "for i in columns:\n",
    "    print(\"La variabile %s ha %d missing value\" % (i, train[i].isnull().values.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     891\n",
       "unique      3\n",
       "top         3\n",
       "freq      491\n",
       "Name: Pclass, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Pclass'] = train['Pclass'].apply(str)\n",
    "train[\"Pclass\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = (\"Pclass\", \"Embarked\")\n",
    "for i in cols:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(train[i].values))\n",
    "    train[i] = le.transform(list(train[i].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age  SibSp  Parch     Fare  Embarked  Sex_female  \\\n",
       "0         0       2  22.0      1      0   7.2500         2           0   \n",
       "1         1       0  38.0      1      0  71.2833         0           1   \n",
       "2         1       2  26.0      0      0   7.9250         2           1   \n",
       "3         1       0  35.0      1      0  53.1000         2           1   \n",
       "4         0       2  35.0      0      0   8.0500         2           0   \n",
       "\n",
       "   Sex_male  \n",
       "0         1  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(train.columns[-1], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Id = test[\"PassengerId\"]\n",
    "test.drop([\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"], axis = 1, inplace = True) #Rimuovo l'id pure dal test e lo salvo in una lista, in modo poi da riattaccarlo per la submission\n",
    "columns_test = test.columns    #risetto le colonne, ora che ne sono state droppate 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST:\n",
      "\n",
      "La variabile Pclass ha 0 missing value\n",
      "La variabile Sex ha 0 missing value\n",
      "La variabile Age ha 0 missing value\n",
      "La variabile SibSp ha 0 missing value\n",
      "La variabile Parch ha 0 missing value\n",
      "La variabile Fare ha 0 missing value\n",
      "La variabile Embarked ha 0 missing value\n"
     ]
    }
   ],
   "source": [
    "test['Age'] = test['Age'].fillna(test['Age'].median())\n",
    "test['Fare'] = test['Fare'].fillna(test['Fare'].median())\n",
    "print(\"TEST:\\n\")\n",
    "for i in columns_test:\n",
    "    print(\"La variabile %s ha %d missing value\" % (i, test[i].isnull().values.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     418\n",
       "unique      3\n",
       "top         3\n",
       "freq      218\n",
       "Name: Pclass, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Pclass'] = test['Pclass'].apply(str)\n",
    "test[\"Pclass\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = (\"Pclass\", \"Embarked\")\n",
    "for i in cols:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(test[i].values))\n",
    "    test[i] = le.transform(list(test[i].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(test.columns[-1], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex_female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age  SibSp  Parch     Fare  Embarked  Sex_female\n",
       "0       2  34.5      0      0   7.8292         1           0\n",
       "1       2  47.0      1      0   7.0000         2           1\n",
       "2       1  62.0      0      0   9.6875         1           0\n",
       "3       2  27.0      0      0   8.6625         2           0\n",
       "4       2  22.0      1      1  12.2875         2           1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programmi\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train = train.Survived.values\n",
    "target_train_nodup = target_train          #lo duplico in modo che più avanti questo non lo trasformerò in un array a due dimensioni, e potrò usarlo per la ROC curve\n",
    "train.drop([\"Survived\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train\n",
    "y = target_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NORMALIZZO TEST E TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaler = preprocessing.MinMaxScaler(feature_range = (0,1))\n",
    "X_norm = df_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_norm = df_scaler.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 7)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 7)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train = np_utils.to_categorical(target_train, 2) #GLI FACCIO CAPIRE CHE IL TARGET è BINARIO E LO METTO SOTTO FORMA DI ARRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creo modello\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(100, input_dim=7, activation='relu'))\n",
    "model.add(layers.Dense(80,  activation='relu'))\n",
    "model.add(layers.Dense(60, activation='relu'))\n",
    "model.add(layers.Dense(50, activation='relu'))\n",
    "model.add(layers.Dense(40, activation='relu'))\n",
    "model.add(layers.Dense(30, activation='relu'))\n",
    "model.add(layers.Dense(25, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='relu'))\n",
    "model.add(layers.Dense(8, activation='relu'))##\n",
    "model.add(layers.Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_180 (Dense)            (None, 100)               800       \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 80)                8080      \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 60)                4860      \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 50)                3050      \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 40)                2040      \n",
      "_________________________________________________________________\n",
      "dense_185 (Dense)            (None, 30)                1230      \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 25)                775       \n",
      "_________________________________________________________________\n",
      "dense_187 (Dense)            (None, 15)                390       \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 8)                 128       \n",
      "_________________________________________________________________\n",
      "dense_189 (Dense)            (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 21,371\n",
      "Trainable params: 21,371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/300\n",
      "623/623 [==============================] - 1s 2ms/step - loss: 0.3491 - acc: 0.8515 - val_loss: 0.5504 - val_acc: 0.8228\n",
      "Epoch 2/300\n",
      "623/623 [==============================] - 0s 94us/step - loss: 0.3270 - acc: 0.8636 - val_loss: 0.5748 - val_acc: 0.8172\n",
      "Epoch 3/300\n",
      "623/623 [==============================] - 0s 96us/step - loss: 0.3301 - acc: 0.8644 - val_loss: 0.6127 - val_acc: 0.8246\n",
      "Epoch 4/300\n",
      "623/623 [==============================] - 0s 93us/step - loss: 0.3290 - acc: 0.8636 - val_loss: 0.5957 - val_acc: 0.8209\n",
      "Epoch 5/300\n",
      "623/623 [==============================] - 0s 93us/step - loss: 0.3353 - acc: 0.8604 - val_loss: 0.5941 - val_acc: 0.8116\n",
      "Epoch 6/300\n",
      "623/623 [==============================] - 0s 98us/step - loss: 0.3256 - acc: 0.8596 - val_loss: 0.6088 - val_acc: 0.8153\n",
      "Epoch 7/300\n",
      "623/623 [==============================] - 0s 90us/step - loss: 0.3278 - acc: 0.8620 - val_loss: 0.6195 - val_acc: 0.7985\n",
      "Epoch 8/300\n",
      "623/623 [==============================] - 0s 125us/step - loss: 0.3285 - acc: 0.8587 - val_loss: 0.6749 - val_acc: 0.8209\n",
      "Epoch 9/300\n",
      "623/623 [==============================] - 0s 115us/step - loss: 0.3336 - acc: 0.8676 - val_loss: 0.5969 - val_acc: 0.8246\n",
      "Epoch 10/300\n",
      "623/623 [==============================] - 0s 114us/step - loss: 0.3313 - acc: 0.8587 - val_loss: 0.5811 - val_acc: 0.8209\n",
      "Epoch 11/300\n",
      "623/623 [==============================] - 0s 91us/step - loss: 0.3203 - acc: 0.8660 - val_loss: 0.6576 - val_acc: 0.8097\n",
      "Epoch 12/300\n",
      "623/623 [==============================] - 0s 86us/step - loss: 0.3336 - acc: 0.8579 - val_loss: 0.6318 - val_acc: 0.8134\n",
      "Epoch 13/300\n",
      "623/623 [==============================] - 0s 94us/step - loss: 0.3438 - acc: 0.8547 - val_loss: 0.5899 - val_acc: 0.8209\n",
      "Epoch 14/300\n",
      "623/623 [==============================] - 0s 86us/step - loss: 0.3246 - acc: 0.8708 - val_loss: 0.5926 - val_acc: 0.8116\n",
      "Epoch 15/300\n",
      "623/623 [==============================] - 0s 88us/step - loss: 0.3244 - acc: 0.8579 - val_loss: 0.5795 - val_acc: 0.8134\n",
      "Epoch 16/300\n",
      "623/623 [==============================] - 0s 88us/step - loss: 0.3301 - acc: 0.8571 - val_loss: 0.5823 - val_acc: 0.8321\n",
      "Epoch 17/300\n",
      "623/623 [==============================] - 0s 90us/step - loss: 0.3316 - acc: 0.8636 - val_loss: 0.6232 - val_acc: 0.8078\n",
      "Epoch 18/300\n",
      "623/623 [==============================] - 0s 178us/step - loss: 0.3317 - acc: 0.8684 - val_loss: 0.5734 - val_acc: 0.8246\n",
      "Epoch 19/300\n",
      "623/623 [==============================] - 0s 186us/step - loss: 0.3294 - acc: 0.8587 - val_loss: 0.6831 - val_acc: 0.7948\n",
      "Epoch 20/300\n",
      "623/623 [==============================] - 0s 154us/step - loss: 0.3254 - acc: 0.8700 - val_loss: 0.6435 - val_acc: 0.8134\n",
      "Epoch 21/300\n",
      "623/623 [==============================] - 0s 117us/step - loss: 0.3230 - acc: 0.8604 - val_loss: 0.5765 - val_acc: 0.8134\n",
      "Epoch 22/300\n",
      "623/623 [==============================] - 0s 107us/step - loss: 0.3309 - acc: 0.8700 - val_loss: 0.5933 - val_acc: 0.8321\n",
      "Epoch 23/300\n",
      "623/623 [==============================] - 0s 125us/step - loss: 0.3213 - acc: 0.8612 - val_loss: 0.6028 - val_acc: 0.8022\n",
      "Epoch 24/300\n",
      "623/623 [==============================] - 0s 118us/step - loss: 0.3286 - acc: 0.8652 - val_loss: 0.6205 - val_acc: 0.8060\n",
      "Epoch 25/300\n",
      "623/623 [==============================] - 0s 98us/step - loss: 0.3344 - acc: 0.8612 - val_loss: 0.6368 - val_acc: 0.8097\n",
      "Epoch 26/300\n",
      "623/623 [==============================] - 0s 96us/step - loss: 0.3188 - acc: 0.8732 - val_loss: 0.6399 - val_acc: 0.7948\n",
      "Epoch 27/300\n",
      "623/623 [==============================] - 0s 86us/step - loss: 0.3400 - acc: 0.8644 - val_loss: 0.7020 - val_acc: 0.8078\n",
      "Epoch 28/300\n",
      "623/623 [==============================] - 0s 154us/step - loss: 0.3264 - acc: 0.8555 - val_loss: 0.6161 - val_acc: 0.8134\n",
      "Epoch 29/300\n",
      "623/623 [==============================] - 0s 138us/step - loss: 0.3290 - acc: 0.8579 - val_loss: 0.5509 - val_acc: 0.8209\n",
      "Epoch 30/300\n",
      "623/623 [==============================] - 0s 131us/step - loss: 0.3247 - acc: 0.8652 - val_loss: 0.6088 - val_acc: 0.8134\n",
      "Epoch 31/300\n",
      "623/623 [==============================] - 0s 107us/step - loss: 0.3238 - acc: 0.8596 - val_loss: 0.6134 - val_acc: 0.8134\n",
      "Epoch 32/300\n",
      "623/623 [==============================] - 0s 128us/step - loss: 0.3163 - acc: 0.8507 - val_loss: 0.6970 - val_acc: 0.8060\n",
      "Epoch 33/300\n",
      "623/623 [==============================] - 0s 107us/step - loss: 0.3347 - acc: 0.8660 - val_loss: 0.5805 - val_acc: 0.8190\n",
      "Epoch 34/300\n",
      "623/623 [==============================] - 0s 118us/step - loss: 0.3380 - acc: 0.8539 - val_loss: 0.5962 - val_acc: 0.8190\n",
      "Epoch 35/300\n",
      "623/623 [==============================] - 0s 94us/step - loss: 0.3179 - acc: 0.8732 - val_loss: 0.6326 - val_acc: 0.8097\n",
      "Epoch 36/300\n",
      "623/623 [==============================] - 0s 80us/step - loss: 0.3187 - acc: 0.8596 - val_loss: 0.5862 - val_acc: 0.8153\n",
      "Epoch 37/300\n",
      "623/623 [==============================] - 0s 86us/step - loss: 0.3217 - acc: 0.8547 - val_loss: 0.5902 - val_acc: 0.8078\n",
      "Epoch 38/300\n",
      "623/623 [==============================] - 0s 88us/step - loss: 0.3236 - acc: 0.8555 - val_loss: 0.6111 - val_acc: 0.8190\n",
      "Epoch 39/300\n",
      "623/623 [==============================] - 0s 83us/step - loss: 0.3300 - acc: 0.8652 - val_loss: 0.6042 - val_acc: 0.8116\n",
      "Epoch 40/300\n",
      "623/623 [==============================] - 0s 107us/step - loss: 0.3177 - acc: 0.8620 - val_loss: 0.6512 - val_acc: 0.8209\n",
      "Epoch 41/300\n",
      "623/623 [==============================] - 0s 109us/step - loss: 0.3343 - acc: 0.8708 - val_loss: 0.6632 - val_acc: 0.8041\n",
      "Epoch 42/300\n",
      "623/623 [==============================] - 0s 123us/step - loss: 0.3101 - acc: 0.8660 - val_loss: 0.6159 - val_acc: 0.8228\n",
      "Epoch 43/300\n",
      "623/623 [==============================] - 0s 110us/step - loss: 0.3300 - acc: 0.8620 - val_loss: 0.6080 - val_acc: 0.8172\n",
      "Epoch 44/300\n",
      "623/623 [==============================] - 0s 96us/step - loss: 0.3157 - acc: 0.8579 - val_loss: 0.6260 - val_acc: 0.8041\n",
      "Epoch 45/300\n",
      "623/623 [==============================] - 0s 102us/step - loss: 0.3155 - acc: 0.8684 - val_loss: 0.6494 - val_acc: 0.8078\n",
      "Epoch 46/300\n",
      "623/623 [==============================] - 0s 91us/step - loss: 0.3134 - acc: 0.8668 - val_loss: 0.5921 - val_acc: 0.8172\n",
      "Epoch 47/300\n",
      "623/623 [==============================] - 0s 80us/step - loss: 0.3190 - acc: 0.8660 - val_loss: 0.6215 - val_acc: 0.8377\n",
      "Epoch 48/300\n",
      "623/623 [==============================] - 0s 88us/step - loss: 0.3288 - acc: 0.8676 - val_loss: 0.6777 - val_acc: 0.8022\n",
      "Epoch 49/300\n",
      "623/623 [==============================] - 0s 82us/step - loss: 0.3173 - acc: 0.8676 - val_loss: 0.5984 - val_acc: 0.8172\n",
      "Epoch 50/300\n",
      "623/623 [==============================] - 0s 93us/step - loss: 0.3084 - acc: 0.8764 - val_loss: 0.6269 - val_acc: 0.8134\n",
      "Epoch 51/300\n",
      "623/623 [==============================] - 0s 94us/step - loss: 0.3216 - acc: 0.8644 - val_loss: 0.5763 - val_acc: 0.8321\n",
      "Epoch 52/300\n",
      "623/623 [==============================] - 0s 98us/step - loss: 0.3300 - acc: 0.8652 - val_loss: 0.6114 - val_acc: 0.8172\n",
      "Epoch 53/300\n",
      "623/623 [==============================] - 0s 99us/step - loss: 0.3115 - acc: 0.8700 - val_loss: 0.6471 - val_acc: 0.8060\n",
      "Epoch 54/300\n",
      "623/623 [==============================] - 0s 90us/step - loss: 0.3139 - acc: 0.8684 - val_loss: 0.6088 - val_acc: 0.8246\n",
      "Epoch 55/300\n",
      "623/623 [==============================] - 0s 102us/step - loss: 0.3237 - acc: 0.8676 - val_loss: 0.6004 - val_acc: 0.8153\n",
      "Epoch 56/300\n",
      "623/623 [==============================] - 0s 88us/step - loss: 0.3171 - acc: 0.8692 - val_loss: 0.6673 - val_acc: 0.8209\n",
      "Epoch 57/300\n",
      "623/623 [==============================] - 0s 91us/step - loss: 0.3235 - acc: 0.8612 - val_loss: 0.6386 - val_acc: 0.8284\n",
      "Epoch 58/300\n",
      "623/623 [==============================] - 0s 86us/step - loss: 0.3169 - acc: 0.8636 - val_loss: 0.7067 - val_acc: 0.8078\n",
      "Epoch 59/300\n",
      "623/623 [==============================] - 0s 109us/step - loss: 0.3143 - acc: 0.8668 - val_loss: 0.6065 - val_acc: 0.8209\n",
      "Epoch 60/300\n",
      "623/623 [==============================] - 0s 109us/step - loss: 0.3186 - acc: 0.8660 - val_loss: 0.6104 - val_acc: 0.8153\n",
      "Epoch 61/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623/623 [==============================] - 0s 98us/step - loss: 0.3108 - acc: 0.8684 - val_loss: 0.6493 - val_acc: 0.8284\n",
      "Epoch 62/300\n",
      "623/623 [==============================] - 0s 83us/step - loss: 0.3149 - acc: 0.8555 - val_loss: 0.6947 - val_acc: 0.8246\n",
      "Epoch 63/300\n",
      "623/623 [==============================] - 0s 91us/step - loss: 0.3275 - acc: 0.8628 - val_loss: 0.7088 - val_acc: 0.7985\n",
      "Epoch 64/300\n",
      "623/623 [==============================] - 0s 82us/step - loss: 0.3114 - acc: 0.8684 - val_loss: 0.6497 - val_acc: 0.8172\n",
      "Epoch 65/300\n",
      "623/623 [==============================] - 0s 83us/step - loss: 0.3212 - acc: 0.8636 - val_loss: 0.6089 - val_acc: 0.8060\n",
      "Epoch 66/300\n",
      "623/623 [==============================] - 0s 85us/step - loss: 0.3266 - acc: 0.8668 - val_loss: 0.6676 - val_acc: 0.8078\n",
      "Epoch 67/300\n",
      "623/623 [==============================] - 0s 85us/step - loss: 0.3103 - acc: 0.8764 - val_loss: 0.5923 - val_acc: 0.8060\n",
      "Epoch 68/300\n",
      "623/623 [==============================] - 0s 80us/step - loss: 0.3139 - acc: 0.8652 - val_loss: 0.6112 - val_acc: 0.8209\n",
      "Epoch 69/300\n",
      "623/623 [==============================] - 0s 101us/step - loss: 0.3106 - acc: 0.8732 - val_loss: 0.5720 - val_acc: 0.8097\n",
      "Epoch 70/300\n",
      "623/623 [==============================] - 0s 85us/step - loss: 0.3105 - acc: 0.8740 - val_loss: 0.6264 - val_acc: 0.8246\n",
      "Epoch 71/300\n",
      "623/623 [==============================] - 0s 80us/step - loss: 0.3112 - acc: 0.8764 - val_loss: 0.6817 - val_acc: 0.8190\n",
      "Epoch 72/300\n",
      "623/623 [==============================] - 0s 83us/step - loss: 0.3133 - acc: 0.8700 - val_loss: 0.6905 - val_acc: 0.8116\n",
      "Epoch 73/300\n",
      "623/623 [==============================] - 0s 83us/step - loss: 0.3143 - acc: 0.8740 - val_loss: 0.6157 - val_acc: 0.8078\n",
      "Epoch 74/300\n",
      "623/623 [==============================] - 0s 85us/step - loss: 0.3110 - acc: 0.8668 - val_loss: 0.7394 - val_acc: 0.8097\n",
      "Epoch 75/300\n",
      "623/623 [==============================] - 0s 83us/step - loss: 0.3287 - acc: 0.8636 - val_loss: 0.6315 - val_acc: 0.8190\n",
      "Epoch 76/300\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.3057 - acc: 0.8652 - val_loss: 0.6599 - val_acc: 0.8134\n",
      "Epoch 77/300\n",
      "623/623 [==============================] - 0s 86us/step - loss: 0.3175 - acc: 0.8612 - val_loss: 0.7290 - val_acc: 0.8172\n",
      "Epoch 78/300\n",
      "623/623 [==============================] - 0s 80us/step - loss: 0.3183 - acc: 0.8724 - val_loss: 0.6296 - val_acc: 0.8209\n",
      "Epoch 79/300\n",
      "623/623 [==============================] - 0s 93us/step - loss: 0.3074 - acc: 0.8604 - val_loss: 0.6952 - val_acc: 0.8246\n",
      "Epoch 80/300\n",
      "623/623 [==============================] - 0s 88us/step - loss: 0.3362 - acc: 0.8555 - val_loss: 0.6441 - val_acc: 0.8134\n",
      "Epoch 81/300\n",
      "623/623 [==============================] - 0s 82us/step - loss: 0.3156 - acc: 0.8652 - val_loss: 0.6094 - val_acc: 0.8172\n",
      "Epoch 82/300\n",
      "623/623 [==============================] - 0s 93us/step - loss: 0.3073 - acc: 0.8596 - val_loss: 0.7235 - val_acc: 0.8172\n",
      "Epoch 83/300\n",
      "623/623 [==============================] - 0s 82us/step - loss: 0.3147 - acc: 0.8692 - val_loss: 0.7350 - val_acc: 0.8116\n",
      "Epoch 84/300\n",
      "623/623 [==============================] - 0s 82us/step - loss: 0.3348 - acc: 0.8491 - val_loss: 0.6378 - val_acc: 0.8265\n",
      "Epoch 85/300\n",
      "623/623 [==============================] - 0s 91us/step - loss: 0.3021 - acc: 0.8676 - val_loss: 0.6553 - val_acc: 0.8172\n",
      "Epoch 86/300\n",
      "623/623 [==============================] - 0s 85us/step - loss: 0.2972 - acc: 0.8716 - val_loss: 0.7355 - val_acc: 0.8116\n",
      "Epoch 87/300\n",
      "623/623 [==============================] - 0s 83us/step - loss: 0.3284 - acc: 0.8652 - val_loss: 0.6584 - val_acc: 0.8134\n",
      "Epoch 88/300\n",
      "623/623 [==============================] - 0s 86us/step - loss: 0.3162 - acc: 0.8636 - val_loss: 0.7000 - val_acc: 0.8134\n",
      "Epoch 89/300\n",
      "623/623 [==============================] - 0s 82us/step - loss: 0.3104 - acc: 0.8644 - val_loss: 0.6736 - val_acc: 0.8190\n",
      "Epoch 90/300\n",
      "623/623 [==============================] - 0s 91us/step - loss: 0.3170 - acc: 0.8668 - val_loss: 0.6714 - val_acc: 0.8134\n",
      "Epoch 91/300\n",
      "623/623 [==============================] - 0s 83us/step - loss: 0.3057 - acc: 0.8716 - val_loss: 0.7103 - val_acc: 0.8041\n",
      "Epoch 92/300\n",
      "623/623 [==============================] - 0s 85us/step - loss: 0.3276 - acc: 0.8596 - val_loss: 0.6577 - val_acc: 0.8172\n",
      "Epoch 93/300\n",
      "623/623 [==============================] - 0s 94us/step - loss: 0.3183 - acc: 0.8587 - val_loss: 0.6463 - val_acc: 0.8209\n",
      "Epoch 94/300\n",
      "623/623 [==============================] - 0s 85us/step - loss: 0.3081 - acc: 0.8708 - val_loss: 0.6579 - val_acc: 0.8265\n",
      "Epoch 95/300\n",
      "623/623 [==============================] - 0s 85us/step - loss: 0.3209 - acc: 0.8660 - val_loss: 0.6657 - val_acc: 0.8209\n",
      "Epoch 96/300\n",
      "623/623 [==============================] - 0s 83us/step - loss: 0.3174 - acc: 0.8628 - val_loss: 0.6392 - val_acc: 0.8134\n",
      "Epoch 97/300\n",
      "623/623 [==============================] - 0s 98us/step - loss: 0.3160 - acc: 0.8708 - val_loss: 0.6228 - val_acc: 0.8172\n",
      "Epoch 98/300\n",
      "623/623 [==============================] - 0s 82us/step - loss: 0.3087 - acc: 0.8692 - val_loss: 0.6868 - val_acc: 0.8209\n",
      "Epoch 99/300\n",
      "623/623 [==============================] - 0s 106us/step - loss: 0.3049 - acc: 0.8700 - val_loss: 0.7010 - val_acc: 0.8302\n",
      "Epoch 100/300\n",
      "623/623 [==============================] - 0s 78us/step - loss: 0.3179 - acc: 0.8660 - val_loss: 0.6417 - val_acc: 0.8190\n",
      "Epoch 101/300\n",
      "623/623 [==============================] - 0s 86us/step - loss: 0.3059 - acc: 0.8620 - val_loss: 0.6222 - val_acc: 0.8060\n",
      "Epoch 102/300\n",
      "623/623 [==============================] - 0s 78us/step - loss: 0.3468 - acc: 0.8620 - val_loss: 0.7065 - val_acc: 0.8172\n",
      "Epoch 103/300\n",
      "623/623 [==============================] - 0s 99us/step - loss: 0.3113 - acc: 0.8604 - val_loss: 0.6446 - val_acc: 0.8153\n",
      "Epoch 104/300\n",
      "623/623 [==============================] - 0s 78us/step - loss: 0.3107 - acc: 0.8692 - val_loss: 0.6398 - val_acc: 0.8190\n",
      "Epoch 105/300\n",
      "623/623 [==============================] - 0s 86us/step - loss: 0.3177 - acc: 0.8555 - val_loss: 0.6182 - val_acc: 0.8097\n",
      "Epoch 106/300\n",
      "623/623 [==============================] - 0s 80us/step - loss: 0.3086 - acc: 0.8652 - val_loss: 0.6642 - val_acc: 0.8172\n",
      "Epoch 107/300\n",
      "623/623 [==============================] - 0s 99us/step - loss: 0.3264 - acc: 0.8644 - val_loss: 0.7048 - val_acc: 0.8209\n",
      "Epoch 108/300\n",
      "623/623 [==============================] - 0s 90us/step - loss: 0.3098 - acc: 0.8612 - val_loss: 0.6742 - val_acc: 0.8284\n",
      "Epoch 109/300\n",
      "623/623 [==============================] - 0s 82us/step - loss: 0.3118 - acc: 0.8636 - val_loss: 0.6354 - val_acc: 0.8284\n",
      "Epoch 110/300\n",
      "623/623 [==============================] - 0s 93us/step - loss: 0.3292 - acc: 0.8636 - val_loss: 0.6398 - val_acc: 0.8078\n",
      "Epoch 111/300\n",
      "623/623 [==============================] - 0s 80us/step - loss: 0.3034 - acc: 0.8684 - val_loss: 0.6823 - val_acc: 0.8172\n",
      "Epoch 112/300\n",
      "623/623 [==============================] - 0s 96us/step - loss: 0.3233 - acc: 0.8636 - val_loss: 0.7292 - val_acc: 0.8116\n",
      "Epoch 113/300\n",
      "623/623 [==============================] - 0s 80us/step - loss: 0.3097 - acc: 0.8700 - val_loss: 0.6884 - val_acc: 0.8209\n",
      "Epoch 114/300\n",
      "623/623 [==============================] - 0s 86us/step - loss: 0.3109 - acc: 0.8660 - val_loss: 0.6426 - val_acc: 0.8172\n",
      "Epoch 115/300\n",
      "623/623 [==============================] - 0s 88us/step - loss: 0.3132 - acc: 0.8716 - val_loss: 0.6464 - val_acc: 0.8134\n",
      "Epoch 116/300\n",
      "623/623 [==============================] - 0s 94us/step - loss: 0.3169 - acc: 0.8612 - val_loss: 0.6475 - val_acc: 0.8078\n",
      "Epoch 117/300\n",
      "623/623 [==============================] - 0s 90us/step - loss: 0.3071 - acc: 0.8652 - val_loss: 0.8771 - val_acc: 0.7985\n",
      "Epoch 118/300\n",
      "623/623 [==============================] - 0s 94us/step - loss: 0.3406 - acc: 0.8708 - val_loss: 0.6566 - val_acc: 0.8097\n",
      "Epoch 119/300\n",
      "623/623 [==============================] - 0s 82us/step - loss: 0.3029 - acc: 0.8628 - val_loss: 0.6739 - val_acc: 0.8209\n",
      "Epoch 120/300\n",
      "623/623 [==============================] - 0s 80us/step - loss: 0.3077 - acc: 0.8604 - val_loss: 0.6203 - val_acc: 0.8209\n",
      "Epoch 121/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623/623 [==============================] - 0s 96us/step - loss: 0.3327 - acc: 0.8732 - val_loss: 0.6808 - val_acc: 0.8097\n",
      "Epoch 122/300\n",
      "623/623 [==============================] - 0s 90us/step - loss: 0.3065 - acc: 0.8652 - val_loss: 0.7108 - val_acc: 0.8190\n",
      "Epoch 123/300\n",
      "623/623 [==============================] - 0s 88us/step - loss: 0.3058 - acc: 0.8604 - val_loss: 0.6680 - val_acc: 0.8097\n",
      "Epoch 124/300\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.3257 - acc: 0.8636 - val_loss: 0.6503 - val_acc: 0.8209\n",
      "Epoch 125/300\n",
      "623/623 [==============================] - 0s 83us/step - loss: 0.3085 - acc: 0.8748 - val_loss: 0.7152 - val_acc: 0.8265\n",
      "Epoch 126/300\n",
      "623/623 [==============================] - 0s 90us/step - loss: 0.3301 - acc: 0.8684 - val_loss: 0.6933 - val_acc: 0.8190\n",
      "Epoch 127/300\n",
      "623/623 [==============================] - 0s 85us/step - loss: 0.3062 - acc: 0.8748 - val_loss: 0.7972 - val_acc: 0.8153\n",
      "Epoch 128/300\n",
      "623/623 [==============================] - 0s 82us/step - loss: 0.3064 - acc: 0.8652 - val_loss: 0.7071 - val_acc: 0.8153\n",
      "Epoch 129/300\n",
      "623/623 [==============================] - 0s 80us/step - loss: 0.3097 - acc: 0.8676 - val_loss: 0.6306 - val_acc: 0.8190\n",
      "Epoch 130/300\n",
      "623/623 [==============================] - 0s 90us/step - loss: 0.3109 - acc: 0.8644 - val_loss: 0.6823 - val_acc: 0.8228\n",
      "Epoch 131/300\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.3126 - acc: 0.8644 - val_loss: 0.7149 - val_acc: 0.8022\n",
      "Epoch 132/300\n",
      "623/623 [==============================] - 0s 80us/step - loss: 0.2985 - acc: 0.8748 - val_loss: 0.9103 - val_acc: 0.8022\n",
      "Epoch 133/300\n",
      "623/623 [==============================] - 0s 80us/step - loss: 0.3278 - acc: 0.8628 - val_loss: 0.6584 - val_acc: 0.8265\n",
      "Epoch 134/300\n",
      "623/623 [==============================] - 0s 83us/step - loss: 0.2998 - acc: 0.8724 - val_loss: 0.7265 - val_acc: 0.8265\n",
      "Epoch 135/300\n",
      "623/623 [==============================] - 0s 88us/step - loss: 0.3234 - acc: 0.8724 - val_loss: 0.6650 - val_acc: 0.8190\n",
      "Epoch 136/300\n",
      "623/623 [==============================] - 0s 82us/step - loss: 0.2971 - acc: 0.8756 - val_loss: 0.6731 - val_acc: 0.8097\n",
      "Epoch 137/300\n",
      "623/623 [==============================] - 0s 106us/step - loss: 0.2985 - acc: 0.8684 - val_loss: 0.7140 - val_acc: 0.8209\n",
      "Epoch 138/300\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.3118 - acc: 0.8644 - val_loss: 0.7528 - val_acc: 0.8190\n",
      "Epoch 139/300\n",
      "623/623 [==============================] - 0s 90us/step - loss: 0.3025 - acc: 0.8684 - val_loss: 0.7004 - val_acc: 0.8116\n",
      "Epoch 140/300\n",
      "623/623 [==============================] - 0s 90us/step - loss: 0.3059 - acc: 0.8628 - val_loss: 0.6677 - val_acc: 0.8022\n",
      "Epoch 141/300\n",
      "623/623 [==============================] - 0s 83us/step - loss: 0.3058 - acc: 0.8652 - val_loss: 0.7321 - val_acc: 0.8078\n",
      "Epoch 142/300\n",
      "623/623 [==============================] - 0s 134us/step - loss: 0.3020 - acc: 0.8700 - val_loss: 0.7204 - val_acc: 0.8209\n",
      "Epoch 143/300\n",
      "623/623 [==============================] - 0s 176us/step - loss: 0.3193 - acc: 0.8596 - val_loss: 0.6638 - val_acc: 0.8209\n",
      "Epoch 144/300\n",
      "623/623 [==============================] - 0s 157us/step - loss: 0.3239 - acc: 0.8684 - val_loss: 0.6896 - val_acc: 0.8134\n",
      "Epoch 145/300\n",
      "623/623 [==============================] - 0s 152us/step - loss: 0.3057 - acc: 0.8620 - val_loss: 0.7345 - val_acc: 0.8116\n",
      "Epoch 146/300\n",
      "623/623 [==============================] - 0s 96us/step - loss: 0.2958 - acc: 0.8836 - val_loss: 0.7108 - val_acc: 0.8209\n",
      "Epoch 147/300\n",
      "623/623 [==============================] - 0s 99us/step - loss: 0.3028 - acc: 0.8764 - val_loss: 0.7193 - val_acc: 0.8228\n",
      "Epoch 148/300\n",
      "623/623 [==============================] - 0s 122us/step - loss: 0.3084 - acc: 0.8668 - val_loss: 0.7184 - val_acc: 0.8209\n",
      "Epoch 149/300\n",
      "623/623 [==============================] - 0s 171us/step - loss: 0.2951 - acc: 0.8724 - val_loss: 0.9634 - val_acc: 0.7985\n",
      "Epoch 150/300\n",
      "623/623 [==============================] - 0s 165us/step - loss: 0.3189 - acc: 0.8620 - val_loss: 0.7257 - val_acc: 0.8172\n",
      "Epoch 151/300\n",
      "623/623 [==============================] - 0s 123us/step - loss: 0.3081 - acc: 0.8676 - val_loss: 0.7009 - val_acc: 0.8190\n",
      "Epoch 152/300\n",
      "623/623 [==============================] - 0s 139us/step - loss: 0.3124 - acc: 0.8748 - val_loss: 0.7152 - val_acc: 0.8116\n",
      "Epoch 153/300\n",
      "623/623 [==============================] - 0s 99us/step - loss: 0.3011 - acc: 0.8748 - val_loss: 0.7414 - val_acc: 0.7985\n",
      "Epoch 154/300\n",
      "623/623 [==============================] - 0s 110us/step - loss: 0.2996 - acc: 0.8732 - val_loss: 0.7581 - val_acc: 0.8116\n",
      "Epoch 155/300\n",
      "623/623 [==============================] - 0s 98us/step - loss: 0.3182 - acc: 0.8700 - val_loss: 0.6836 - val_acc: 0.8190\n",
      "Epoch 156/300\n",
      "623/623 [==============================] - 0s 88us/step - loss: 0.2945 - acc: 0.8676 - val_loss: 0.7306 - val_acc: 0.8265\n",
      "Epoch 157/300\n",
      "623/623 [==============================] - 0s 149us/step - loss: 0.2965 - acc: 0.8748 - val_loss: 0.7179 - val_acc: 0.8265\n",
      "Epoch 158/300\n",
      "623/623 [==============================] - 0s 158us/step - loss: 0.3125 - acc: 0.8620 - val_loss: 0.6607 - val_acc: 0.8284\n",
      "Epoch 159/300\n",
      "623/623 [==============================] - 0s 157us/step - loss: 0.3152 - acc: 0.8644 - val_loss: 0.8560 - val_acc: 0.8022\n",
      "Epoch 160/300\n",
      "623/623 [==============================] - 0s 133us/step - loss: 0.3135 - acc: 0.8676 - val_loss: 0.7241 - val_acc: 0.8209\n",
      "Epoch 161/300\n",
      "623/623 [==============================] - 0s 144us/step - loss: 0.2990 - acc: 0.8612 - val_loss: 0.7154 - val_acc: 0.8209\n",
      "Epoch 162/300\n",
      "623/623 [==============================] - 0s 104us/step - loss: 0.2937 - acc: 0.8740 - val_loss: 0.8426 - val_acc: 0.8246\n",
      "Epoch 163/300\n",
      "623/623 [==============================] - 0s 98us/step - loss: 0.3173 - acc: 0.8756 - val_loss: 0.7480 - val_acc: 0.8265\n",
      "Epoch 164/300\n",
      "623/623 [==============================] - 0s 88us/step - loss: 0.3049 - acc: 0.8644 - val_loss: 0.7532 - val_acc: 0.8321\n",
      "Epoch 165/300\n",
      "623/623 [==============================] - 0s 90us/step - loss: 0.3076 - acc: 0.8668 - val_loss: 0.7371 - val_acc: 0.8265\n",
      "Epoch 166/300\n",
      "623/623 [==============================] - 0s 82us/step - loss: 0.3253 - acc: 0.8563 - val_loss: 0.6439 - val_acc: 0.8246\n",
      "Epoch 167/300\n",
      "623/623 [==============================] - 0s 88us/step - loss: 0.2935 - acc: 0.8692 - val_loss: 0.7342 - val_acc: 0.8097\n",
      "Epoch 168/300\n",
      "623/623 [==============================] - 0s 78us/step - loss: 0.3071 - acc: 0.8772 - val_loss: 0.7594 - val_acc: 0.8209\n",
      "Epoch 169/300\n",
      "623/623 [==============================] - 0s 83us/step - loss: 0.3007 - acc: 0.8772 - val_loss: 0.6835 - val_acc: 0.8172\n",
      "Epoch 170/300\n",
      "623/623 [==============================] - 0s 85us/step - loss: 0.3047 - acc: 0.8756 - val_loss: 0.7651 - val_acc: 0.8190\n",
      "Epoch 171/300\n",
      "623/623 [==============================] - 0s 83us/step - loss: 0.3237 - acc: 0.8676 - val_loss: 0.6837 - val_acc: 0.8246\n",
      "Epoch 172/300\n",
      "623/623 [==============================] - 0s 86us/step - loss: 0.2964 - acc: 0.8748 - val_loss: 0.7603 - val_acc: 0.8134\n",
      "Epoch 173/300\n",
      "623/623 [==============================] - 0s 109us/step - loss: 0.2968 - acc: 0.8724 - val_loss: 0.7362 - val_acc: 0.8190\n",
      "Epoch 174/300\n",
      "623/623 [==============================] - 0s 101us/step - loss: 0.3063 - acc: 0.8708 - val_loss: 0.7068 - val_acc: 0.8097\n",
      "Epoch 175/300\n",
      "623/623 [==============================] - 0s 96us/step - loss: 0.3084 - acc: 0.8628 - val_loss: 0.7140 - val_acc: 0.8078\n",
      "Epoch 176/300\n",
      "623/623 [==============================] - 0s 85us/step - loss: 0.2974 - acc: 0.8668 - val_loss: 0.6826 - val_acc: 0.8153\n",
      "Epoch 177/300\n",
      "623/623 [==============================] - 0s 85us/step - loss: 0.2938 - acc: 0.8764 - val_loss: 0.7340 - val_acc: 0.8246\n",
      "Epoch 178/300\n",
      "623/623 [==============================] - 0s 83us/step - loss: 0.3813 - acc: 0.8539 - val_loss: 0.6640 - val_acc: 0.8228\n",
      "Epoch 179/300\n",
      "623/623 [==============================] - 0s 90us/step - loss: 0.2955 - acc: 0.8668 - val_loss: 0.6715 - val_acc: 0.8172\n",
      "Epoch 180/300\n",
      "623/623 [==============================] - 0s 82us/step - loss: 0.2962 - acc: 0.8764 - val_loss: 0.8131 - val_acc: 0.8097\n",
      "Epoch 181/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623/623 [==============================] - 0s 86us/step - loss: 0.3121 - acc: 0.8652 - val_loss: 0.7529 - val_acc: 0.8190\n",
      "Epoch 182/300\n",
      "623/623 [==============================] - 0s 86us/step - loss: 0.3026 - acc: 0.8684 - val_loss: 0.7432 - val_acc: 0.8190\n",
      "Epoch 183/300\n",
      "623/623 [==============================] - 0s 90us/step - loss: 0.3085 - acc: 0.8620 - val_loss: 0.7302 - val_acc: 0.8172\n",
      "Epoch 184/300\n",
      "623/623 [==============================] - 0s 82us/step - loss: 0.3085 - acc: 0.8732 - val_loss: 0.6789 - val_acc: 0.8284\n",
      "Epoch 185/300\n",
      "623/623 [==============================] - 0s 80us/step - loss: 0.2957 - acc: 0.8732 - val_loss: 0.7392 - val_acc: 0.8134\n",
      "Epoch 186/300\n",
      "623/623 [==============================] - 0s 83us/step - loss: 0.3101 - acc: 0.8724 - val_loss: 0.6877 - val_acc: 0.8134\n",
      "Epoch 187/300\n",
      "623/623 [==============================] - 0s 83us/step - loss: 0.3193 - acc: 0.8724 - val_loss: 0.6457 - val_acc: 0.8172\n",
      "Epoch 188/300\n",
      "623/623 [==============================] - 0s 91us/step - loss: 0.2991 - acc: 0.8724 - val_loss: 0.7290 - val_acc: 0.8246\n",
      "Epoch 189/300\n",
      "623/623 [==============================] - 0s 99us/step - loss: 0.3120 - acc: 0.8724 - val_loss: 0.6541 - val_acc: 0.8302\n",
      "Epoch 190/300\n",
      "623/623 [==============================] - 0s 160us/step - loss: 0.2961 - acc: 0.8684 - val_loss: 0.6922 - val_acc: 0.8284\n",
      "Epoch 191/300\n",
      "623/623 [==============================] - 0s 110us/step - loss: 0.3053 - acc: 0.8732 - val_loss: 0.6698 - val_acc: 0.8209\n",
      "Epoch 192/300\n",
      "623/623 [==============================] - 0s 117us/step - loss: 0.2994 - acc: 0.8716 - val_loss: 0.7645 - val_acc: 0.8060\n",
      "Epoch 193/300\n",
      "623/623 [==============================] - 0s 139us/step - loss: 0.3041 - acc: 0.8660 - val_loss: 0.7033 - val_acc: 0.8228\n",
      "Epoch 194/300\n",
      "623/623 [==============================] - 0s 149us/step - loss: 0.2910 - acc: 0.8684 - val_loss: 0.6702 - val_acc: 0.8358\n",
      "Epoch 195/300\n",
      "623/623 [==============================] - 0s 155us/step - loss: 0.3065 - acc: 0.8628 - val_loss: 0.7276 - val_acc: 0.8078\n",
      "Epoch 196/300\n",
      "623/623 [==============================] - 0s 102us/step - loss: 0.3111 - acc: 0.8684 - val_loss: 0.7349 - val_acc: 0.8228\n",
      "Epoch 197/300\n",
      "623/623 [==============================] - 0s 118us/step - loss: 0.2952 - acc: 0.8668 - val_loss: 0.8437 - val_acc: 0.8209\n",
      "Epoch 198/300\n",
      "623/623 [==============================] - 0s 91us/step - loss: 0.3081 - acc: 0.8563 - val_loss: 0.6966 - val_acc: 0.8414\n",
      "Epoch 199/300\n",
      "623/623 [==============================] - 0s 90us/step - loss: 0.3015 - acc: 0.8740 - val_loss: 0.7628 - val_acc: 0.8228\n",
      "Epoch 200/300\n",
      "623/623 [==============================] - 0s 158us/step - loss: 0.3065 - acc: 0.8724 - val_loss: 0.7454 - val_acc: 0.8172\n",
      "Epoch 201/300\n",
      "623/623 [==============================] - 0s 152us/step - loss: 0.2905 - acc: 0.8716 - val_loss: 0.8116 - val_acc: 0.8172\n",
      "Epoch 202/300\n",
      "623/623 [==============================] - 0s 125us/step - loss: 0.3179 - acc: 0.8732 - val_loss: 0.7365 - val_acc: 0.8302\n",
      "Epoch 203/300\n",
      "623/623 [==============================] - 0s 96us/step - loss: 0.3221 - acc: 0.8660 - val_loss: 0.6714 - val_acc: 0.8134\n",
      "Epoch 204/300\n",
      "623/623 [==============================] - 0s 91us/step - loss: 0.2883 - acc: 0.8796 - val_loss: 0.6864 - val_acc: 0.8190\n",
      "Epoch 205/300\n",
      "623/623 [==============================] - 0s 86us/step - loss: 0.2897 - acc: 0.8780 - val_loss: 0.7976 - val_acc: 0.8284\n",
      "Epoch 206/300\n",
      "623/623 [==============================] - 0s 93us/step - loss: 0.3302 - acc: 0.8587 - val_loss: 0.6607 - val_acc: 0.8228\n",
      "Epoch 207/300\n",
      "623/623 [==============================] - 0s 170us/step - loss: 0.2954 - acc: 0.8660 - val_loss: 0.7689 - val_acc: 0.8116\n",
      "Epoch 208/300\n",
      "623/623 [==============================] - 0s 146us/step - loss: 0.3034 - acc: 0.8796 - val_loss: 0.7885 - val_acc: 0.8134\n",
      "Epoch 209/300\n",
      "623/623 [==============================] - 0s 117us/step - loss: 0.3293 - acc: 0.8636 - val_loss: 0.6844 - val_acc: 0.8209\n",
      "Epoch 210/300\n",
      "623/623 [==============================] - 0s 128us/step - loss: 0.2872 - acc: 0.8764 - val_loss: 0.7256 - val_acc: 0.8060\n",
      "Epoch 211/300\n",
      "623/623 [==============================] - 0s 106us/step - loss: 0.3116 - acc: 0.8700 - val_loss: 0.7257 - val_acc: 0.8209\n",
      "Epoch 212/300\n",
      "623/623 [==============================] - 0s 122us/step - loss: 0.2976 - acc: 0.8668 - val_loss: 0.6691 - val_acc: 0.8134\n",
      "Epoch 213/300\n",
      "623/623 [==============================] - 0s 106us/step - loss: 0.2972 - acc: 0.8676 - val_loss: 0.7446 - val_acc: 0.8097\n",
      "Epoch 214/300\n",
      "623/623 [==============================] - 0s 85us/step - loss: 0.3044 - acc: 0.8772 - val_loss: 0.7613 - val_acc: 0.8022\n",
      "Epoch 215/300\n",
      "623/623 [==============================] - 0s 80us/step - loss: 0.3050 - acc: 0.8628 - val_loss: 0.7399 - val_acc: 0.8060\n",
      "Epoch 216/300\n",
      "623/623 [==============================] - 0s 101us/step - loss: 0.3019 - acc: 0.8652 - val_loss: 0.7915 - val_acc: 0.8153\n",
      "Epoch 217/300\n",
      "623/623 [==============================] - 0s 166us/step - loss: 0.2953 - acc: 0.8756 - val_loss: 0.7723 - val_acc: 0.8116\n",
      "Epoch 218/300\n",
      "623/623 [==============================] - 0s 150us/step - loss: 0.3030 - acc: 0.8692 - val_loss: 0.8102 - val_acc: 0.7929\n",
      "Epoch 219/300\n",
      "623/623 [==============================] - 0s 104us/step - loss: 0.2939 - acc: 0.8644 - val_loss: 0.7511 - val_acc: 0.8097\n",
      "Epoch 220/300\n",
      "623/623 [==============================] - 0s 115us/step - loss: 0.2927 - acc: 0.8748 - val_loss: 0.7580 - val_acc: 0.8097\n",
      "Epoch 221/300\n",
      "623/623 [==============================] - 0s 122us/step - loss: 0.3071 - acc: 0.8668 - val_loss: 0.7577 - val_acc: 0.7892\n",
      "Epoch 222/300\n",
      "623/623 [==============================] - 0s 107us/step - loss: 0.2956 - acc: 0.8756 - val_loss: 0.7468 - val_acc: 0.8022\n",
      "Epoch 223/300\n",
      "623/623 [==============================] - 0s 115us/step - loss: 0.3254 - acc: 0.8708 - val_loss: 0.6693 - val_acc: 0.8022\n",
      "Epoch 224/300\n",
      "623/623 [==============================] - 0s 104us/step - loss: 0.2970 - acc: 0.8724 - val_loss: 0.6939 - val_acc: 0.8022\n",
      "Epoch 225/300\n",
      "623/623 [==============================] - 0s 82us/step - loss: 0.2963 - acc: 0.8692 - val_loss: 0.7433 - val_acc: 0.8116\n",
      "Epoch 226/300\n",
      "623/623 [==============================] - 0s 122us/step - loss: 0.2942 - acc: 0.8708 - val_loss: 0.7358 - val_acc: 0.8209\n",
      "Epoch 227/300\n",
      "623/623 [==============================] - 0s 141us/step - loss: 0.3059 - acc: 0.8692 - val_loss: 0.7646 - val_acc: 0.8022\n",
      "Epoch 228/300\n",
      "623/623 [==============================] - 0s 109us/step - loss: 0.2989 - acc: 0.8756 - val_loss: 0.6831 - val_acc: 0.8190\n",
      "Epoch 229/300\n",
      "623/623 [==============================] - 0s 122us/step - loss: 0.2951 - acc: 0.8764 - val_loss: 0.7341 - val_acc: 0.8172\n",
      "Epoch 230/300\n",
      "623/623 [==============================] - 0s 138us/step - loss: 0.3085 - acc: 0.8628 - val_loss: 0.7944 - val_acc: 0.8060\n",
      "Epoch 231/300\n",
      "623/623 [==============================] - 0s 107us/step - loss: 0.2840 - acc: 0.8724 - val_loss: 0.7748 - val_acc: 0.8153\n",
      "Epoch 232/300\n",
      "623/623 [==============================] - 0s 149us/step - loss: 0.3043 - acc: 0.8732 - val_loss: 0.7723 - val_acc: 0.8078\n",
      "Epoch 233/300\n",
      "623/623 [==============================] - 0s 136us/step - loss: 0.2851 - acc: 0.8860 - val_loss: 0.7246 - val_acc: 0.8190\n",
      "Epoch 234/300\n",
      "623/623 [==============================] - 0s 114us/step - loss: 0.3069 - acc: 0.8740 - val_loss: 0.7617 - val_acc: 0.8209\n",
      "Epoch 235/300\n",
      "623/623 [==============================] - 0s 107us/step - loss: 0.2970 - acc: 0.8740 - val_loss: 0.7548 - val_acc: 0.8209\n",
      "Epoch 236/300\n",
      "623/623 [==============================] - 0s 106us/step - loss: 0.3036 - acc: 0.8764 - val_loss: 0.7255 - val_acc: 0.8060\n",
      "Epoch 237/300\n",
      "623/623 [==============================] - 0s 101us/step - loss: 0.2988 - acc: 0.8796 - val_loss: 0.8006 - val_acc: 0.8041\n",
      "Epoch 238/300\n",
      "623/623 [==============================] - 0s 123us/step - loss: 0.3447 - acc: 0.8555 - val_loss: 0.6634 - val_acc: 0.8134\n",
      "Epoch 239/300\n",
      "623/623 [==============================] - 0s 118us/step - loss: 0.2910 - acc: 0.8644 - val_loss: 0.7252 - val_acc: 0.8190\n",
      "Epoch 240/300\n",
      "623/623 [==============================] - 0s 118us/step - loss: 0.3072 - acc: 0.8756 - val_loss: 0.7205 - val_acc: 0.8228\n",
      "Epoch 241/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623/623 [==============================] - 0s 120us/step - loss: 0.2984 - acc: 0.8692 - val_loss: 0.6653 - val_acc: 0.7985\n",
      "Epoch 242/300\n",
      "623/623 [==============================] - 0s 147us/step - loss: 0.3156 - acc: 0.8636 - val_loss: 0.6610 - val_acc: 0.8190\n",
      "Epoch 243/300\n",
      "623/623 [==============================] - 0s 133us/step - loss: 0.3149 - acc: 0.8644 - val_loss: 0.7669 - val_acc: 0.8060\n",
      "Epoch 244/300\n",
      "623/623 [==============================] - 0s 101us/step - loss: 0.2851 - acc: 0.8780 - val_loss: 0.7043 - val_acc: 0.8209\n",
      "Epoch 245/300\n",
      "623/623 [==============================] - 0s 123us/step - loss: 0.2906 - acc: 0.8764 - val_loss: 0.8710 - val_acc: 0.8022\n",
      "Epoch 246/300\n",
      "623/623 [==============================] - 0s 99us/step - loss: 0.3081 - acc: 0.8692 - val_loss: 0.6896 - val_acc: 0.8134\n",
      "Epoch 247/300\n",
      "623/623 [==============================] - 0s 181us/step - loss: 0.2919 - acc: 0.8756 - val_loss: 0.7003 - val_acc: 0.8358\n",
      "Epoch 248/300\n",
      "623/623 [==============================] - 0s 157us/step - loss: 0.3234 - acc: 0.8844 - val_loss: 0.6652 - val_acc: 0.8153\n",
      "Epoch 249/300\n",
      "623/623 [==============================] - 0s 101us/step - loss: 0.3102 - acc: 0.8708 - val_loss: 0.7051 - val_acc: 0.8246\n",
      "Epoch 250/300\n",
      "623/623 [==============================] - 0s 106us/step - loss: 0.2893 - acc: 0.8716 - val_loss: 0.7015 - val_acc: 0.8340\n",
      "Epoch 251/300\n",
      "623/623 [==============================] - 0s 94us/step - loss: 0.2937 - acc: 0.8812 - val_loss: 0.7621 - val_acc: 0.8134\n",
      "Epoch 252/300\n",
      "623/623 [==============================] - 0s 86us/step - loss: 0.2866 - acc: 0.8732 - val_loss: 0.8773 - val_acc: 0.8041\n",
      "Epoch 253/300\n",
      "623/623 [==============================] - 0s 86us/step - loss: 0.3138 - acc: 0.8652 - val_loss: 0.7742 - val_acc: 0.8190\n",
      "Epoch 254/300\n",
      "623/623 [==============================] - 0s 88us/step - loss: 0.2924 - acc: 0.8716 - val_loss: 0.7876 - val_acc: 0.8209\n",
      "Epoch 255/300\n",
      "623/623 [==============================] - 0s 88us/step - loss: 0.3106 - acc: 0.8700 - val_loss: 0.6684 - val_acc: 0.8134\n",
      "Epoch 256/300\n",
      "623/623 [==============================] - 0s 91us/step - loss: 0.2822 - acc: 0.8684 - val_loss: 0.7713 - val_acc: 0.8209\n",
      "Epoch 257/300\n",
      "623/623 [==============================] - 0s 90us/step - loss: 0.2990 - acc: 0.8804 - val_loss: 0.7523 - val_acc: 0.8228\n",
      "Epoch 258/300\n",
      "623/623 [==============================] - 0s 91us/step - loss: 0.3025 - acc: 0.8796 - val_loss: 0.7675 - val_acc: 0.8060\n",
      "Epoch 259/300\n",
      "623/623 [==============================] - 0s 90us/step - loss: 0.3040 - acc: 0.8788 - val_loss: 0.8137 - val_acc: 0.7780\n",
      "Epoch 260/300\n",
      "623/623 [==============================] - 0s 107us/step - loss: 0.2869 - acc: 0.8748 - val_loss: 0.8568 - val_acc: 0.8116\n",
      "Epoch 261/300\n",
      "623/623 [==============================] - 0s 98us/step - loss: 0.3069 - acc: 0.8804 - val_loss: 0.7304 - val_acc: 0.8153\n",
      "Epoch 262/300\n",
      "623/623 [==============================] - 0s 91us/step - loss: 0.2973 - acc: 0.8756 - val_loss: 0.7039 - val_acc: 0.8116\n",
      "Epoch 263/300\n",
      "623/623 [==============================] - 0s 85us/step - loss: 0.3083 - acc: 0.8716 - val_loss: 0.7065 - val_acc: 0.8116\n",
      "Epoch 264/300\n",
      "623/623 [==============================] - 0s 88us/step - loss: 0.2933 - acc: 0.8708 - val_loss: 0.7499 - val_acc: 0.8116\n",
      "Epoch 265/300\n",
      "623/623 [==============================] - 0s 85us/step - loss: 0.2840 - acc: 0.8796 - val_loss: 0.8043 - val_acc: 0.8097\n",
      "Epoch 266/300\n",
      "623/623 [==============================] - 0s 90us/step - loss: 0.3525 - acc: 0.8676 - val_loss: 0.6878 - val_acc: 0.8228\n",
      "Epoch 267/300\n",
      "623/623 [==============================] - 0s 90us/step - loss: 0.3337 - acc: 0.8692 - val_loss: 0.7116 - val_acc: 0.8116\n",
      "Epoch 268/300\n",
      "623/623 [==============================] - 0s 94us/step - loss: 0.2962 - acc: 0.8772 - val_loss: 0.8193 - val_acc: 0.7985\n",
      "Epoch 269/300\n",
      "623/623 [==============================] - 0s 98us/step - loss: 0.3289 - acc: 0.8700 - val_loss: 0.6560 - val_acc: 0.8116\n",
      "Epoch 270/300\n",
      "623/623 [==============================] - 0s 104us/step - loss: 0.3038 - acc: 0.8700 - val_loss: 0.7618 - val_acc: 0.8041\n",
      "Epoch 271/300\n",
      "623/623 [==============================] - 0s 82us/step - loss: 0.3124 - acc: 0.8579 - val_loss: 0.7140 - val_acc: 0.8153\n",
      "Epoch 272/300\n",
      "623/623 [==============================] - 0s 102us/step - loss: 0.2963 - acc: 0.8748 - val_loss: 0.7489 - val_acc: 0.8022\n",
      "Epoch 273/300\n",
      "623/623 [==============================] - 0s 83us/step - loss: 0.2903 - acc: 0.8756 - val_loss: 0.7665 - val_acc: 0.8209\n",
      "Epoch 274/300\n",
      "623/623 [==============================] - 0s 99us/step - loss: 0.3108 - acc: 0.8700 - val_loss: 0.6656 - val_acc: 0.8041\n",
      "Epoch 275/300\n",
      "623/623 [==============================] - 0s 85us/step - loss: 0.2860 - acc: 0.8716 - val_loss: 0.6783 - val_acc: 0.8134\n",
      "Epoch 276/300\n",
      "623/623 [==============================] - 0s 85us/step - loss: 0.2909 - acc: 0.8756 - val_loss: 0.7032 - val_acc: 0.7948\n",
      "Epoch 277/300\n",
      "623/623 [==============================] - 0s 94us/step - loss: 0.2900 - acc: 0.8844 - val_loss: 0.6642 - val_acc: 0.8284\n",
      "Epoch 278/300\n",
      "623/623 [==============================] - 0s 85us/step - loss: 0.3030 - acc: 0.8756 - val_loss: 0.7187 - val_acc: 0.8153\n",
      "Epoch 279/300\n",
      "623/623 [==============================] - 0s 93us/step - loss: 0.2876 - acc: 0.8836 - val_loss: 0.7894 - val_acc: 0.8172\n",
      "Epoch 280/300\n",
      "623/623 [==============================] - 0s 90us/step - loss: 0.3009 - acc: 0.8716 - val_loss: 0.6395 - val_acc: 0.8358\n",
      "Epoch 281/300\n",
      "623/623 [==============================] - 0s 85us/step - loss: 0.3131 - acc: 0.8604 - val_loss: 0.7032 - val_acc: 0.8265\n",
      "Epoch 282/300\n",
      "623/623 [==============================] - 0s 90us/step - loss: 0.2927 - acc: 0.8708 - val_loss: 0.7367 - val_acc: 0.8153\n",
      "Epoch 283/300\n",
      "623/623 [==============================] - 0s 90us/step - loss: 0.2948 - acc: 0.8836 - val_loss: 0.7961 - val_acc: 0.8209\n",
      "Epoch 284/300\n",
      "623/623 [==============================] - 0s 85us/step - loss: 0.3065 - acc: 0.8716 - val_loss: 0.7142 - val_acc: 0.8153\n",
      "Epoch 285/300\n",
      "623/623 [==============================] - 0s 90us/step - loss: 0.2975 - acc: 0.8780 - val_loss: 0.6666 - val_acc: 0.8414\n",
      "Epoch 286/300\n",
      "623/623 [==============================] - 0s 90us/step - loss: 0.3196 - acc: 0.8828 - val_loss: 0.7492 - val_acc: 0.8284\n",
      "Epoch 287/300\n",
      "623/623 [==============================] - 0s 86us/step - loss: 0.2950 - acc: 0.8692 - val_loss: 0.7463 - val_acc: 0.8078\n",
      "Epoch 288/300\n",
      "623/623 [==============================] - 0s 130us/step - loss: 0.2925 - acc: 0.8644 - val_loss: 0.7713 - val_acc: 0.8172\n",
      "Epoch 289/300\n",
      "623/623 [==============================] - 0s 134us/step - loss: 0.2941 - acc: 0.8756 - val_loss: 0.6687 - val_acc: 0.8190\n",
      "Epoch 290/300\n",
      "623/623 [==============================] - 0s 133us/step - loss: 0.3171 - acc: 0.8668 - val_loss: 0.6322 - val_acc: 0.8228\n",
      "Epoch 291/300\n",
      "623/623 [==============================] - 0s 136us/step - loss: 0.2834 - acc: 0.8804 - val_loss: 0.7590 - val_acc: 0.8153\n",
      "Epoch 292/300\n",
      "623/623 [==============================] - 0s 117us/step - loss: 0.2890 - acc: 0.8724 - val_loss: 0.7680 - val_acc: 0.7985\n",
      "Epoch 293/300\n",
      "623/623 [==============================] - 0s 117us/step - loss: 0.2914 - acc: 0.8820 - val_loss: 0.8696 - val_acc: 0.7966\n",
      "Epoch 294/300\n",
      "623/623 [==============================] - 0s 104us/step - loss: 0.2947 - acc: 0.8636 - val_loss: 0.7974 - val_acc: 0.7966\n",
      "Epoch 295/300\n",
      "623/623 [==============================] - 0s 125us/step - loss: 0.3173 - acc: 0.8596 - val_loss: 0.6532 - val_acc: 0.8153\n",
      "Epoch 296/300\n",
      "623/623 [==============================] - 0s 128us/step - loss: 0.3373 - acc: 0.8644 - val_loss: 0.7659 - val_acc: 0.8190\n",
      "Epoch 297/300\n",
      "623/623 [==============================] - 0s 115us/step - loss: 0.2860 - acc: 0.8820 - val_loss: 0.7934 - val_acc: 0.8246\n",
      "Epoch 298/300\n",
      "623/623 [==============================] - 0s 128us/step - loss: 0.2971 - acc: 0.8700 - val_loss: 0.7230 - val_acc: 0.8022\n",
      "Epoch 299/300\n",
      "623/623 [==============================] - 0s 134us/step - loss: 0.2861 - acc: 0.8748 - val_loss: 0.8131 - val_acc: 0.8078\n",
      "Epoch 300/300\n",
      "623/623 [==============================] - 0s 93us/step - loss: 0.3012 - acc: 0.8732 - val_loss: 0.7313 - val_acc: 0.7985\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer= 'RMSProp',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_norm, target_train,\n",
    "                    batch_size = 35, epochs = 300,\n",
    "                    verbose = 1, validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTO IL MODELLO SULLO STESSO TRAIN PER OSSERVARE LA ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 45us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.40940891291557335, 0.8630751964754261]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_norm, target_train, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict(X_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_train = pd.DataFrame(pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.188532e-01</td>\n",
       "      <td>0.091161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.394208e-11</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.967721e-01</td>\n",
       "      <td>0.449988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.661946e-06</td>\n",
       "      <td>0.999997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.248112e-01</td>\n",
       "      <td>0.162820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1\n",
       "0  9.188532e-01  0.091161\n",
       "1  6.394208e-11  1.000000\n",
       "2  5.967721e-01  0.449988\n",
       "3  1.661946e-06  0.999997\n",
       "4  8.248112e-01  0.162820"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_train = pred_train[1]\n",
    "surv_train = []\n",
    "for i in col_train:\n",
    "    if i < 0.5:\n",
    "        surv_train.append(\"0\")\n",
    "    else:\n",
    "        surv_train.append(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpr = pd.DataFrame({\"Probability(1)\" : pred_train[1], \"Survived\": surv_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Probability(1)</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.091161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.449988</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.162820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Probability(1) Survived\n",
       "0        0.091161        0\n",
       "1        1.000000        1\n",
       "2        0.449988        0\n",
       "3        0.999997        1\n",
       "4        0.162820        0"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainpr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpr[\"Survived\"].astype(int)\n",
    "surv_array = np.array(trainpr[\"Survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[505,  77],\n",
       "       [ 44, 265]], dtype=int64)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(surv_array.astype(int), target_train_nodup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = model.predict_proba(X_norm)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(target_train_nodup, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC CURVE ON TRAIN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2054723a828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLASSIFICATION ON TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.966041</td>\n",
       "      <td>0.037359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.983713</td>\n",
       "      <td>0.017622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.890255</td>\n",
       "      <td>0.111064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.773684</td>\n",
       "      <td>0.254826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.872021</td>\n",
       "      <td>0.119464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.413455</td>\n",
       "      <td>0.586532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.955753</td>\n",
       "      <td>0.055930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.556166</td>\n",
       "      <td>0.425679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.991292</td>\n",
       "      <td>0.012794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.966041  0.037359\n",
       "1  0.983713  0.017622\n",
       "2  0.999995  0.000005\n",
       "3  0.890255  0.111064\n",
       "4  0.773684  0.254826\n",
       "5  0.872021  0.119464\n",
       "6  0.413455  0.586532\n",
       "7  0.955753  0.055930\n",
       "8  0.556166  0.425679\n",
       "9  0.991292  0.012794"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = pred[1]\n",
    "surv = []\n",
    "for i in col1:\n",
    "    if i < 0.5:\n",
    "        surv.append(\"0\")\n",
    "    else:\n",
    "        surv.append(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "consegna = pd.DataFrame({\"PassengerId\" : test_Id, \"Prob(Survived)\" : pred[1], \"Survived\" : surv})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "consegna.set_index(\"PassengerId\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "consegna.drop(\"Prob(Survived)\", axis = 1).to_csv(\"subm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
